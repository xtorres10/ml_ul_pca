{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1EQ5G9rQcwE"
      },
      "source": [
        "# Clustering and PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Toc_OzXYQcwH"
      },
      "source": [
        "### Mushroom Dataset\n",
        "\n",
        "Podeis obtener el conjunto de datos en el siguiente enlace:\n",
        "\n",
        "[Mushroom Dataset](https://www.kaggle.com/uciml/mushroom-classification)\n",
        "\n",
        "Como podréis comprobar, hay muchas variables, todas ellas categóricas, por lo que exploraciones con scatterplot no nos serán útiles como en otros casos.\n",
        "\n",
        "La variable a predecir ``class`` es binaria.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJc845c11KbK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWIOS2y_QcwH"
      },
      "outputs": [],
      "source": [
        "# Carga de librerías, las que hemos considerado básicas, añadid lo que queráis :)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KbJPDrpQcwI"
      },
      "source": [
        "### Leer conjunto de datos y primer vistazo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFJoAIsVQcwI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Leer el csv y sacar por pantalla las cinco primeras filas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dePM9qXKQcwJ"
      },
      "source": [
        "### Exploración de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45TsUuwkQcwJ"
      },
      "outputs": [],
      "source": [
        "# Descripción del conjunto de datos, estándard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJG-fxzJQcwJ"
      },
      "outputs": [],
      "source": [
        "# Información sobre el tipo de datos de cada feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md7i8gXBQcwJ"
      },
      "source": [
        "#### Calcular el número de nulos de cada feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xXz4mT0QcwJ",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Igual que otras veces, una linea, contar los nulos por variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJv-ez3WQcwK"
      },
      "source": [
        "#### Buscar valores extraños. Para ello, ver los valores únicos en cada feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUZ2EHmTQcwK"
      },
      "outputs": [],
      "source": [
        "# Obtener un nuevo dataframe de dos columnas donde en la primera estén las features (features) y en la otra los valores únicos\n",
        "# asociados (n_values)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXIyz_tdQcwK"
      },
      "source": [
        "#### Tratar aquellos valores que entendamos que sean nulos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVQnxK1gQcwK"
      },
      "outputs": [],
      "source": [
        "# Imputaciones. Podéis quitar esos puntos (fila entera), imputar con la moda o dejar ese valor como una posibilidad más."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dbmx1Z7QcwK"
      },
      "source": [
        "#### Mirad cuántos valores hay en cada feature, ¿Todas las features aportan información? Si alguna no aporta información, eliminadla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts2xeUavQcwK"
      },
      "outputs": [],
      "source": [
        "# Dejar por el camino si procede."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dX1LM1VQcwK"
      },
      "source": [
        "#### Separar entre variables predictoras y variables a predecir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS9HEA2eQcwK"
      },
      "outputs": [],
      "source": [
        "# La variable que trata de predecir este conjunto de datos es 'class'.\n",
        "y =\n",
        "X ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN1fZZfZQcwL"
      },
      "source": [
        "#### Codificar correctamente las variables categóricas a numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4l92dfEQcwL"
      },
      "outputs": [],
      "source": [
        "# One Hot Encoder (una linea)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBBAM0bzQcwL"
      },
      "source": [
        "#### Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHxqeJQqQcwL"
      },
      "outputs": [],
      "source": [
        "# Os lo dejamos a todos igual\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sL57bzCQcwL"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhAhJqbKQcwM"
      },
      "source": [
        "Es un conjunto de datos del que aún no hemos visto nada (no tenemos graficas) así que vamos a hacer algunas. Tenemos el problema de que son muchas variables, **PCA al rescate**: le pedimos que nos de dos dimensiones y las pintamos, sabemos que serán **aquellas que retengan más información**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3232KSn9QcwM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "pca =       # metodo de sklearn\n",
        "pca.fit(X_train)\n",
        "\n",
        "# Representar en un scatterplot y poner en color las etiquetas de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMYH_Hv0QcwM"
      },
      "source": [
        "Parece que está bastante separadito, parece que a ojo mucho se puede ver :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdE0AvlKQcwM"
      },
      "source": [
        "Igualmente, vamos a entrenar un clasificador a ver qué tal lo hace antes de editar más"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKQqz_EPQcwM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. Definir el clasificador y el número de estimadores\n",
        "# 2. Entrenar en train\n",
        "# 3. Calcular la precisión sobre test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PACQlU5_QcwM"
      },
      "source": [
        "Es un conjunto sencillo y Random Forest es muy bueno en su trabajo, Igualmente, vamos a ver qué tamaño tenemos de dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODibK0D2QcwN"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rEVhvRaQcwN"
      },
      "source": [
        "¿Muchas features no? Vamos a reducir las usando PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEJPZw_cQcwN",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "n_features = # definir un rango de valores a probar\n",
        "scores = []\n",
        "\n",
        "for n in n_features:\n",
        "\n",
        "    # Hacer PCA sobre X_train\n",
        "    # 1. Definir PCA\n",
        "    # 2. Aprender PCA sobre X_train\n",
        "\n",
        "    # Entrenar Random Forest\n",
        "    # 1. Definir el RF\n",
        "    # 2. Entrenar clasificador\n",
        "\n",
        "    # Guardar el score\n",
        "\n",
        "\n",
        "sns.lineplot(x=n_features, y=scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKjl6aHiQcwN"
      },
      "source": [
        "Vale, estamos viendo que a partir de unas 10 features ya tenemos el score que queríamos y además hemos reducido las variables a un 10% de las que teníamos, incluso menos que las variables originales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jvqa-leQcwN"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWiMHKUdQcwN"
      },
      "source": [
        "Viendo que el conjunto de datos es sencillito, podemos intentar hacer algo de clustering a ver qué información podemos obtener.\n",
        "\n",
        "El primer paso va a ser importar la función de Kmeans de sklearn, y a partir de ahi, vamos a buscar el valor óptimo de clusters. Como hemos visto anteriormente, este valor lo obtenemos, por ejemplo, del codo de la gráfica que representa el total de las distancias de los puntos a los centros de los clusters asociados. Os dejo la página de la documentación de sklearn para que lo busquéis:\n",
        "\n",
        "[K-Means on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
        "\n",
        "Con esto solo hay que ahora generar los modelos de kmeans, evaluar y pintar la gráfica para los valores de ``k`` que establezcais.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DV0IXFncQcwO"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "scores = []\n",
        "k_values = # definir un rango\n",
        "for a in k_values:\n",
        "\n",
        "    # Definir Kmeans y ajustar\n",
        "    # Guardar la predicción\n",
        "\n",
        "sns.lineplot(x=k_values, y=scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSgPG286QcwO"
      },
      "source": [
        "Con el valor que hayáis obtenido de la gráfica, podéis obtener una buena aproximación de Kmeans y con ello podemos pasar a explorar cómo de bien han separado la información los distintos clusters. Para ello, se va a hacer un ``catplot``, seaborn os lo hará solito. Con esto lo que se pretende ver es la distribución de la varaible a predecir en función del cluster que haya determinado Kmeans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa7XfETyQcwO",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Aprender Kmeans con el valor de K obtenido.\n",
        "\n",
        "kmeans = # Definir y entrenar Kmeans.\n",
        "\n",
        "# Preparar el catplot.\n",
        "\n",
        "\n",
        "# Pintar.\n",
        "ax = sns.catplot(col=, x=, data=, kind='count',col_wrap=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzMUKFwzQcwO"
      },
      "source": [
        "Vamos a ver qué tal queda esto pintado. Para ello, repetimos el scatterplot de antes pero usando como color el cluster asignado por kmeans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjhjuexcQcwO",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Entrenar PCA para representar.\n",
        "\n",
        "# Usar un color por cada cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0q-ZDhQQcwO"
      },
      "source": [
        "¿Es bastante parecido no? No es tan bueno como el Random Forest, pero ha conseguido identificar bastante bien los distintos puntos del dataset sin utilizar las etiquetas. De hecho, el diagrama de factor que hemos visto antes muestra que solo un par de clusters son imprecisos. Si no hubieramos tenido etiquetas esta aproximacion nos hubiera ayudado mucho a clasificar los distintos tipos de hongos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
